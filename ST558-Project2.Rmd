---
title: "ST558-Project 2"
output: github_document
params:
  data_channel: "bus"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Introduction

TBD: Mark

# Data

```{r}
library(tidyverse)

set.seed(3)

# Import News
news <- read_csv("OnlineNewsPopularity/OnlineNewsPopularity.csv")

# Split by channel
news <- news %>%
  pivot_longer(starts_with("data_channel_is_"), 
               names_prefix = "data_channel_is_",
               names_to = "channel") %>%
  filter(value == 1) %>%
  select(-value) %>%
  split(.$channel) 

# Work on channel supplied by params
newsData <- news[[params$data_channel]]
```

## Splitting the data

```{r}
library(caret)

## Setup new data set with only variables of interest
newsSubFinal <- newsData %>% 
  select(LDA_02, avg_negative_polarity, average_token_length, 
         max_negative_polarity, kw_max_avg, LDA_03, kw_avg_avg, 
         weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, 
         weekday_is_thursday, weekday_is_friday, 
         weekday_is_saturday, weekday_is_sunday, shares)

## Train/Test Split
trainIndex <- createDataPartition(newsSubFinal$shares, p = .70, list = FALSE)
newsTrain <- newsSubFinal[trainIndex, ]
newsTest <- newsSubFinal[-trainIndex, ]
```

# Summarizations

Correlation Plots for Numeric variables used

```{r}
## It seems like very few observations have shares greater than 1500
## Fixing range for better visuals
ggplot(data = newsTrain, aes(shares, LDA_02)) +
  geom_point(color="darkseagreen") +
  labs(x = "Shares", y = "LDA Topic 2 Closeness", title = "LDA2 v. Shares") +
  xlim(0, 15000) 

ggplot(data = newsTrain, aes(shares, avg_negative_polarity)) +
  geom_point(color="darkseagreen") +
  labs(x = "Shares", y = "Average Polarity of Negative Words", 
       title = "Avg. Negative Polarity v. Shares") +
  xlim(0, 15000) 

ggplot(data = newsTrain, aes(shares, average_token_length)) +
  geom_point(color="darkorange") +
  labs(x = "Shares", y = "Avg. Word Length in Content", 
       title = "Avg. Word Length v. Shares") +
  xlim(0, 15000) 

ggplot(data = newsTrain, aes(shares, max_negative_polarity)) +
  geom_point(color="darkorange") +
  labs(x = "Shares", y = "Max. Polarity of Negative Words", 
       title = "Max Negative Polarity v. Shares") +
  xlim(0, 15000) 

ggplot(data = newsTrain, aes(shares, kw_max_avg)) +
  geom_point(color="aquamarine2") +
  labs(x = "Shares", y = "Avg. Keyword/Max. Shares", 
       title = "Avg. Keyword/Max. Shares v. Shares") +
  xlim(0, 15000)

ggplot(data = newsTrain, aes(shares, LDA_03)) +
  geom_point(color="aquamarine2") +
  labs(x = "Shares", y = "LDA Topic 3 Closeness", 
       title = "LDA3 v. Shares") +
  xlim(0, 15000)

ggplot(data = newsTrain, aes(shares, kw_avg_avg)) +
  geom_point(color="darkseagreen") +
  labs(x = "Shares", y = "Avg. Keyword/Avg. Shares", 
       title = "Avg. Keyword/Shares v. Shares") +
  xlim(0, 15000) 
```
  
Boxplot for categorical variable used:

```{r}
# Get days of week in a single column and plot visuals based on weekday for shares
newsTrainDaysSub <- newsTrain %>% select(shares, weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday, weekday_is_sunday)

newsTrainDaysSubLong <- pivot_longer(data = newsTrainDaysSub, cols = c(weekday_is_monday, weekday_is_tuesday, weekday_is_wednesday, weekday_is_thursday, weekday_is_friday, weekday_is_saturday, weekday_is_sunday), names_to = "Day")

ggplot(newsTrainDaysSubLong, aes(shares)) +
  geom_boxplot(aes(fill=Day)) +
  scale_fill_discrete(labels = c("Friday", "Monday",  "Saturday","Sunday", "Thursday","Tuesday", "Wednesday")) +
  theme(axis.ticks.y = element_blank(),
        axis.text.y = element_blank()) +
  xlim(0, 15000)
```

Each group member is responsible for producing some summary statistics (means, sds, contingency tables, etc.) and for producing at least three graphs (each) of the data.

# Modeling

The first group member should fit a random forest model and the second group member should
fit a boosted tree model. Both models should be chosen using cross-validation.

Prior to the models fit using linear regression, the first group member should provide a short
but thorough explanation of the idea of a linear regression model.

Prior to each ensemble model, you should provide a short but reasonably thorough explanation
of the ensemble model you are using (so one for each group member).

## Linear Regression

```{r}
fullLM <- train(shares ~ ., data = newsTrain,
      method = "lm",
      preProcess = c("center", "scale"),
      trControl = trainControl(method = "cv", number= 5))
pred <- predict(fullLM, select(newsTest, -shares))
postResample(pred, newsTest$shares)
```

## Random Forest

TBD: Jovanni

## Boosted Tree

TBD: Mark

# Comparison

This can be done by one group member and the automation done by the other (see below).

# Automation

Below is the manual part that has to be done in order to kick off the  
automated reports
Let's create the file names and params for the render code.

```{r echo = FALSE, eval = FALSE}
## Create file names
data_channels <- names(news)
output_file <- paste0(data_channels, ".html")

## Create list for each data channel with just the channel name param.
params <- lapply(data_channels, FUN = function(x){list(data_channel = x)})

## Put into df
reports <- tibble(output_file, params)

## Render code
apply(reports, MARGIN = 1,
      FUN = function(x){
        rmarkdown::render(input = "ST558-Project2.Rmd",
               output_format = "github_document",
               output_file = x[[1]],
               params = x[[2]])
      })
```
